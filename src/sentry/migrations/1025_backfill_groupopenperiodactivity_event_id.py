# Generated by Django 5.2.8 on 2026-02-09 18:53

import logging
from typing import Any

from django.db import connection, migrations
from django.db.backends.base.schema import BaseDatabaseSchemaEditor
from django.db.migrations.state import StateApps

from sentry.new_migrations.migrations import CheckedMigration
from sentry.utils.iterators import chunked
from sentry.utils.query import RangeQuerySetWrapperWithProgressBarApprox

logger = logging.getLogger(__name__)

BATCH_SIZE = 1000

# OpenPeriodActivityType.OPENED
OPENED = 1


def _flush_batch(cursor: Any, batch: list[tuple[int, str]]) -> None:
    values_clause = ", ".join(["(%s, %s)"] * len(batch))
    params: list[int | str] = []
    for activity_id, event_id in batch:
        params.extend([activity_id, event_id])

    cursor.execute(
        f"""
        UPDATE sentry_groupopenperiodactivity
        SET event_id = data.event_id
        FROM (VALUES {values_clause}) AS data (id, event_id)
        WHERE sentry_groupopenperiodactivity.id = data.id
            AND sentry_groupopenperiodactivity.event_id IS NULL
        """,
        params,
    )


def backfill_event_id_to_activity(apps: StateApps, schema_editor: BaseDatabaseSchemaEditor) -> None:
    GroupOpenPeriod = apps.get_model("sentry", "GroupOpenPeriod")
    GroupOpenPeriodActivity = apps.get_model("sentry", "GroupOpenPeriodActivity")

    cursor = connection.cursor()
    total_processed = 0
    total_updated = 0

    for chunk in chunked(
        RangeQuerySetWrapperWithProgressBarApprox(
            GroupOpenPeriodActivity.objects.all().values_list(
                "id", "group_open_period_id", "type", "event_id"
            ),
            result_value_getter=lambda item: item[0],
        ),
        BATCH_SIZE,
    ):
        chunk = [
            (activity_id, open_period_id)
            for activity_id, open_period_id, type_, event_id in chunk
            if type_ == OPENED and event_id is None
        ]
        total_processed += BATCH_SIZE
        if not chunk:
            if total_processed % (BATCH_SIZE * 10) == 0:
                logger.info(
                    "backfill_event_id_to_activity: processed %d rows, updated %d",
                    total_processed,
                    total_updated,
                )
            continue

        open_period_ids = [open_period_id for _, open_period_id in chunk]
        event_ids_by_open_period = dict(
            GroupOpenPeriod.objects.filter(
                id__in=open_period_ids,
                event_id__isnull=False,
            ).values_list("id", "event_id")
        )

        batch = []
        for activity_id, open_period_id in chunk:
            event_id = event_ids_by_open_period.get(open_period_id)
            if event_id is not None:
                batch.append((activity_id, event_id))

        if batch:
            _flush_batch(cursor, batch)
            total_updated += len(batch)

        if total_processed % (BATCH_SIZE * 10) == 0:
            logger.info(
                "backfill_event_id_to_activity: processed %d rows, updated %d",
                total_processed,
                total_updated,
            )

    logger.info(
        "backfill_event_id_to_activity: complete, processed %d rows, updated %d",
        total_processed,
        total_updated,
    )


class Migration(CheckedMigration):
    # This flag is used to mark that a migration shouldn't be automatically run in production.
    # This should only be used for operations where it's safe to run the migration after your
    # code has deployed. So this should not be used for most operations that alter the schema
    # of a table.
    # Here are some things that make sense to mark as post deployment:
    # - Large data migrations. Typically we want these to be run manually so that they can be
    #   monitored and not block the deploy for a long period of time while they run.
    # - Adding indexes to large tables. Since this can take a long time, we'd generally prefer to
    #   run this outside deployments so that we don't block them. Note that while adding an index
    #   is a schema change, it's completely safe to run the operation after the code has deployed.
    # Once deployed, run these manually via: https://develop.sentry.dev/database-migrations/#migration-deployment

    is_post_deployment = True

    dependencies = [
        ("sentry", "1024_delete_never_active_users_without_emails_self_hosted"),
    ]

    operations = [
        migrations.RunPython(
            backfill_event_id_to_activity,
            migrations.RunPython.noop,
            hints={"tables": ["sentry_groupopenperiod", "sentry_groupopenperiodactivity"]},
        ),
    ]
